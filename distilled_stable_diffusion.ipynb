{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ed135-fbce-4494-9e44-009d384c7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the packages using pip\n",
    "!pip install --quiet git+https://github.com/huggingface/diffusers.git@d420d71398d9c5a8d9a5f95ba2bdb6fe3d8ae31f\n",
    "!pip install --quiet ipython-autotime\n",
    "!pip install --quiet transformers==4.34.1 accelerate==0.24.0 safetensors==0.4.0\n",
    "!pip install --quiet ipyplot\n",
    "!pip install gradio\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd51926-d1be-44a5-8948-4a873f772e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import gradio as gr\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionPipeline, DiffusionPipeline \n",
    "import torch\n",
    "import ipyplot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408c562-c273-4e9f-b868-7d48e310fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline for ssd-1b\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\"segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "\n",
    "prompt = \"Cinematic, breathtaking, sleek, a white elegant cat amidst a dense foggy London alley, poised beneath a lamp post, Striking image, 8K, Desktop background, Immensely sharp.\"\n",
    "neg_prompt = \"ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft\"\n",
    "\n",
    "image = pipe(prompt=prompt, negative_prompt=neg_prompt).images[0]\n",
    "\n",
    "image.save(\"test.jpg\")\n",
    "\n",
    "ipyplot.plot_images([image],img_width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da2d4f-3f9a-4bbc-aa4b-958e7d94cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The Renaissance Astrounaut\"\n",
    "neg_prompt = \"ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft\"\n",
    "\n",
    "allimages = pipe(prompt=prompt, negative_prompt=neg_prompt,\n",
    "                 guidance_scale=7.5,num_inference_steps=30,\n",
    "                 num_images_per_prompt=2).images\n",
    "\n",
    "images = [image for image in allimages]\n",
    "\n",
    "for idx, image_file in enumerate(allimages, 1):\n",
    "    image_file.save(f\"test{idx}.jpg\")\n",
    "\n",
    "ipyplot.plot_images(images,img_width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf1263-a5fd-49d5-aa5c-ff2f3fee9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to use in the gradio web ui\n",
    "def gen_image(text, neg_prompt):\n",
    "    return pipe(text,\n",
    "                negative_prompt=neg_prompt,\n",
    "                guidance_scale=7.5,\n",
    "                num_inference_steps=30).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ac4d3-6103-48ef-a1c0-4c73d04d42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the gen function \n",
    "gen_image(\"an orange cat staring off with pretty eyes\", \n",
    "         \"ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, \n",
    "          \"out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, \n",
    "          bad anatomy, blurred, watermark, grainy, signature, cut off, draft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f70c12e-0e4f-44ba-9af3-4bc864bf8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a gradio web ui\n",
    "txt = gr.Textbox(label=\"prompt\")\n",
    "txt_2 = gr.Textbox(label=\"neg_prompt\")\n",
    "\n",
    "demo = gr.Interface(fn=gen_image, inputs=[txt, txt_2], \n",
    "                    outputs=\"image\", title = \"Generate A.I.image using Distill Stable DiffusionüòÅ\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bfb9c7-4054-4418-91eb-cce6b15d1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the pipeline for all the 4 diffusion model\n",
    "ssd_1b = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, \n",
    "    variant=\"fp16\").to(\"cuda\")\n",
    "\n",
    "distilled = StableDiffusionPipeline.from_pretrained(\n",
    "    \"nota-ai/bk-sdm-small\", torch_dtype=torch.float16, use_safetensors=True,\n",
    ").to(\"cuda\")\n",
    "\n",
    "original = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16, use_safetensors=True,\n",
    ").to(\"cuda\")\n",
    "\n",
    "SDXL_Original = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, \n",
    "    use_safetensors=True, variant=\"fp16\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097d83e-9fc2-4137-88d8-8e7ec5b615a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "generator = torch.manual_seed(seed)\n",
    "\n",
    "NUM_ITERS_TO_RUN = 3\n",
    "NUM_INFERENCE_STEPS = 25\n",
    "NUM_IMAGES_PER_PROMPT = 4\n",
    "\n",
    "prompt = \"The Robotic Baroque Battle\"\n",
    "\n",
    "start = time.time_ns()\n",
    "for _ in range(NUM_ITERS_TO_RUN):\n",
    "    images = ssd_1b(\n",
    "        prompt,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        generator=generator,\n",
    "        num_images_per_prompt=NUM_IMAGES_PER_PROMPT\n",
    "    ).images\n",
    "end = time.time_ns()\n",
    "original_sd = f\"{(end - start) / 1e6:.1f}\"\n",
    "\n",
    "print(f\"Execution time -- {original_sd} ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf31a3-19c7-4308-b33c-53c21ecb9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    ipyplot.plot_images([image],img_width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b5b8b-2906-43d8-9eb2-46a651b959ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "generator = torch.manual_seed(seed)\n",
    "\n",
    "NUM_ITERS_TO_RUN = 3\n",
    "NUM_INFERENCE_STEPS = 25\n",
    "NUM_IMAGES_PER_PROMPT = 4\n",
    "\n",
    "prompt = \"The Robotic Baroque Battle\"\n",
    "\n",
    "start = time.time_ns()\n",
    "for _ in range(NUM_ITERS_TO_RUN):\n",
    "    images = SDXL_Original(\n",
    "        prompt,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        generator=generator,\n",
    "        num_images_per_prompt=NUM_IMAGES_PER_PROMPT\n",
    "    ).images\n",
    "end = time.time_ns()\n",
    "original_sd = f\"{(end - start) / 1e6:.1f}\"\n",
    "\n",
    "print(f\"Execution time -- {original_sd} ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620452a-eb6b-4649-bda9-b44487f9eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    ipyplot.plot_images([image],img_width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef9cebd-8605-487e-b03b-ae70157b6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "generator = torch.manual_seed(seed)\n",
    "\n",
    "NUM_ITERS_TO_RUN = 3\n",
    "NUM_INFERENCE_STEPS = 25\n",
    "NUM_IMAGES_PER_PROMPT = 4\n",
    "\n",
    "prompt = \"The Robotic Baroque Battle\"\n",
    "\n",
    "start = time.time_ns()\n",
    "for _ in range(NUM_ITERS_TO_RUN):\n",
    "    images = original(\n",
    "        prompt,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        generator=generator,\n",
    "        num_images_per_prompt=NUM_IMAGES_PER_PROMPT\n",
    "    ).images\n",
    "end = time.time_ns()\n",
    "original_sd = f\"{(end - start) / 1e6:.1f}\"\n",
    "\n",
    "print(f\"Execution time -- {original_sd} ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d59e789-29a4-49b9-bf6a-dcb07393c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    ipyplot.plot_images([image],img_width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173574dd-3505-4f93-96e4-41537a8add9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "generator = torch.manual_seed(seed)\n",
    "\n",
    "NUM_ITERS_TO_RUN = 3\n",
    "NUM_INFERENCE_STEPS = 25\n",
    "NUM_IMAGES_PER_PROMPT = 4\n",
    "\n",
    "prompt = \"The Robotic Baroque Battle\"\n",
    "\n",
    "start = time.time_ns()\n",
    "for _ in range(NUM_ITERS_TO_RUN):\n",
    "    images = distilled(\n",
    "        prompt,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        generator=generator,\n",
    "        num_images_per_prompt=NUM_IMAGES_PER_PROMPT\n",
    "    ).images\n",
    "end = time.time_ns()\n",
    "\n",
    "distilled_sd = f\"{(end - start) / 1e6:.1f}\"\n",
    "print(f\"Execution time -- {distilled_sd} ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438c83e-3c0d-439b-831e-1e1a00625ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    ipyplot.plot_images([image],img_width=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
